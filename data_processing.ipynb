{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('./data/full/gt.txt', sep=\";\", header=None)\n",
    "data.columns = [\"img\", \"x1\", \"y1\", \"x2\", \"y2\", \"id\"]\n",
    "\n",
    "data['width'] = 1360\n",
    "data['height'] = 800\n",
    "\n",
    "xtrain = data.iloc[:852]\n",
    "xtest = data.iloc[852:]\n",
    "\n",
    "xtrain.to_csv('./data/full_png/train.csv', index=False)\n",
    "xtest.to_csv('./data/full_png/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Modify the class labels as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for red sign classification, drop the images with no red signs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "xtrain = pd.read_csv('./data/train.csv')\n",
    "\n",
    "xtrain = xtrain[xtrain.id != 6]\n",
    "xtrain = xtrain[xtrain.id != 12]\n",
    "\n",
    "for i in range(32, 43):\n",
    "    xtrain = xtrain[xtrain.id != i]\n",
    "        \n",
    "xtrain.to_csv('./data/train_new2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for red sign detection, drop the images with no red signs\n",
    "#additionally, change the class for the remaining images to 1 - representing they all belong to the same class of red signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import io\n",
    "import random\n",
    "import shutil\n",
    "import configparser\n",
    "import pylab as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "def create_tf_record(examples_list, output_filename):\n",
    "    \n",
    "    writer = tf.python_io.TFRecordWriter(output_filename)\n",
    "    for tf_example in examples_list:\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print(\"Successful created record files\")\n",
    "    \n",
    "def dict_to_tf_example(img_path,\n",
    "                       group,\n",
    "                       gt_label,\n",
    "                       ignore_difficult_instances=False):\n",
    "    \"\"\"Convert gt derived dict to tf.Example proto.\n",
    "    Notice that this function normalizes the bounding box coordinates provided\n",
    "    by the raw data.\n",
    "    \"\"\"\n",
    "    with tf.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = (group.img[:-3] + 'png')\n",
    "    image_format = b'png'\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "    \n",
    "    for index, row in group.object.iterrows():\n",
    "        xmin.append(row['x1'] / width)\n",
    "        xmax.append(row['x2'] / width)\n",
    "        ymin.append(row['y1'] / height)\n",
    "        ymax.append(row['y2'] / height)\n",
    "        #print (index)\n",
    "        #print (gt_label[int(row['id'])])\n",
    "        classes_text.append(gt_label[int(row['id'])].encode('utf8'))\n",
    "        classes.append(int(row['id']))\n",
    "    \n",
    "    #save_img_with_box(image, group, filename)\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "      'image/format': dataset_util.bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return example\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['img', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(img, gb.get_group(x)) for img, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "def csv_record(csv, gt_label, out='out.record'):\n",
    "\n",
    "    examples = pd.read_csv(csv)\n",
    "    grouped = split(examples, 'img')\n",
    "    out_examples = []\n",
    "\n",
    "    for group in grouped:\n",
    "        img_path = os.path.join(train_img_dir, group.img)\n",
    "        img_path = img_path[:-3] + \"png\"\n",
    "        #print(group.img)\n",
    "        #print(img_path)\n",
    "        tf_example = dict_to_tf_example(img_path, group, gt_label)\n",
    "        out_examples.append(tf_example)\n",
    "\n",
    "    output = os.path.join(data_dir, out)\n",
    "    create_tf_record(out_examples, output)\n",
    "    print(out + ' has been successful created')\n",
    "    \n",
    "def main():\n",
    "    \n",
    "    gt_label = {1:'speed limit 30', 2:'speed limit 50', 3:'speed limit 60', 4:'speed limit 70', 5:'speed limit 80', 6:'speed limit 20', 7:'speed limit 100', 8:'speed limit 120', 9:'no overtaking', 10:'no overtaking (trucks)', 11:'priority at next intersection', 13:'give way', 14:'stop', 15:'no traffic both ways', 16:'no trucks', 17:'no entry', 18:'danger', 19:'bend left', 20:'bend right', 21:'bend', 22:'uneven road', 23:'slippery road', 24:'road narrows', 25:'construction', 26:'traffic signal', 27:'pedestrian crossing', 28:'school crossing', 29:'cycles crossing', 30:'snow', 31:'animals'}\n",
    "    csv_record(train_gt_path, gt_label, 'train.record')\n",
    "    csv_record(test_gt_path, gt_label, 'test.record')\n",
    "   \n",
    "data_dir = './data/class_data'\n",
    "train_img_dir = './images'\n",
    "train_gt_path = os.path.join(data_dir, 'train.csv')\n",
    "test_gt_path = os.path.join(data_dir, 'test.csv')\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytensor)",
   "language": "python",
   "name": "pytensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
